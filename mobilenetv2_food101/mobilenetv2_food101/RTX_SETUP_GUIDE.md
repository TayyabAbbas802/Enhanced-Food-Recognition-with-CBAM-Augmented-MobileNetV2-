# RTX 3070 Setup and Training Guide

## üöÄ Quick Start for RTX 3070

This guide will help you set up and run the optimized training on your RTX 3070 system.

---

## System Requirements

‚úÖ **Your System**:
- GPU: NVIDIA RTX 3070 (8GB VRAM)
- CPU: AMD Ryzen 5 5600X
- RAM: 16GB
- OS: Windows 10/11 or Linux

---

## Step 1: Install CUDA PyTorch

### Windows:
```cmd
# Install CUDA PyTorch
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
pip install tqdm scikit-learn
```

### Linux:
```bash
# Install CUDA PyTorch
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
pip3 install tqdm scikit-learn
```

---

## Step 2: Transfer Files

Copy these files from your MacBook to RTX machine:

**Required Files**:
1. `cbam.py` - CBAM attention module
2. `mobilenetv2_cbam.py` - Enhanced MobileNetV2
3. `train_rtx.py` - RTX-optimized training script

**Optional** (will auto-download):
- Food-101 dataset (~5GB)

---

## Step 3: Verify CUDA

```python
import torch
print(f"PyTorch: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"CUDA Version: {torch.version.cuda}")
print(f"GPU: {torch.cuda.get_device_name(0)}")
```

Expected output:
```
PyTorch: 2.x.x
CUDA Available: True
CUDA Version: 11.8
GPU: NVIDIA GeForce RTX 3070
```

---

## Step 4: Start Training

### Option 1: Standard Training (Recommended)
```bash
python train_rtx.py --epochs 50 -j 8 -b 256 --lr 0.001 --pretrained FOOD101
```

**Expected**: 85-87% accuracy in ~5-7 hours

### Option 2: With Mixed Precision (Faster - 2x speedup)
```bash
python train_rtx.py --epochs 50 -j 8 -b 256 --lr 0.001 --pretrained --amp FOOD101
```

**Expected**: 85-87% accuracy in ~3-4 hours ‚ö°

---

## RTX 3070 Optimizations

### What's Optimized:

1. **Larger Batch Size**: 256 (vs 64 on MacBook)
   - Better GPU utilization
   - Faster training

2. **More Workers**: 8 (vs 4 on MacBook)
   - Ryzen 5 5600X has 6 cores/12 threads
   - Faster data loading

3. **Mixed Precision (FP16)**: Optional `--amp` flag
   - 2x faster training
   - Same accuracy
   - Uses Tensor Cores

4. **Persistent Workers**: Keep workers alive
   - Faster epoch transitions
   - Better memory usage

5. **cuDNN Benchmark**: Auto-enabled
   - Finds fastest algorithms
   - 10-20% speedup

---

## Performance Comparison

| System | GPU | Batch | Time/Epoch | 50 Epochs | Speedup |
|--------|-----|-------|------------|-----------|---------|
| MacBook | AMD (MPS) | 64 | 67 min | 56 hours | 1x |
| **RTX 3070** | **CUDA** | **256** | **6-8 min** | **5-7 hours** | **8-10x** |
| **RTX 3070 + FP16** | **CUDA** | **256** | **3-4 min** | **3-4 hours** | **14-16x** |

---

## Training Commands

### Full Training (50 epochs, best accuracy)
```bash
# Standard
python train_rtx.py --epochs 50 -j 8 -b 256 --lr 0.001 --pretrained FOOD101

# With FP16 (faster)
python train_rtx.py --epochs 50 -j 8 -b 256 --lr 0.001 --pretrained --amp FOOD101
```

### Quick Test (10 epochs)
```bash
python train_rtx.py --epochs 10 -j 8 -b 256 --lr 0.001 --pretrained FOOD101
```

### Resume from Checkpoint
```bash
python train_rtx.py --resume checkpoint_rtx_epoch25.pth.tar --epochs 50 -j 8 -b 256 --lr 0.001 --pretrained FOOD101
```

---

## Monitoring Training

### Windows (PowerShell):
```powershell
Get-Content training_output.log -Wait -Tail 20
```

### Linux:
```bash
tail -f training_output.log
```

### Check GPU Usage:
```bash
# Windows/Linux
nvidia-smi

# Watch continuously
watch -n 1 nvidia-smi
```

---

## Expected Output

```
============================================================
RTX 3070 Optimized Training Configuration:
  Model: MobileNetV2-CBAM
  GPU: NVIDIA GeForce RTX 3070
  Epochs: 50
  Batch size: 256
  Workers: 8
  Learning rate: 0.001
  Optimizer: Adam
  Scheduler: CosineAnnealingLR
  Label smoothing: 0.1
  Mixed Precision (FP16): True
  Expected time: ~3-4 hours
============================================================

Epoch: [0][50/296]  Time 0.4  Data 0.05  
Loss 2.8145  Acc@1 52.67  Acc@5 78.34
```

---

## Troubleshooting

### Out of Memory (OOM)
```bash
# Reduce batch size to 128
python train_rtx.py --epochs 50 -j 8 -b 128 --lr 0.001 --pretrained FOOD101
```

### Slow Data Loading
```bash
# Reduce workers to 4
python train_rtx.py --epochs 50 -j 4 -b 256 --lr 0.001 --pretrained FOOD101
```

### CUDA Not Available
```bash
# Reinstall CUDA PyTorch
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

---

## File Structure

```
mobilenetv2_food101/
‚îú‚îÄ‚îÄ cbam.py                    # CBAM attention module
‚îú‚îÄ‚îÄ mobilenetv2_cbam.py        # Enhanced MobileNetV2
‚îú‚îÄ‚îÄ train_rtx.py               # RTX-optimized training ‚≠ê
‚îú‚îÄ‚îÄ FOOD101/                   # Dataset (auto-downloads)
‚îú‚îÄ‚îÄ checkpoint_rtx_epoch*.pth.tar  # Checkpoints
‚îî‚îÄ‚îÄ model_best_rtx.pth.tar     # Best model
```

---

## Expected Results

After 50 epochs with RTX 3070:

| Metric | Value |
|--------|-------|
| Top-1 Accuracy | 85-87% |
| Top-5 Accuracy | 96-97% |
| Training Time | 5-7 hours (standard) |
| Training Time | 3-4 hours (with FP16) |
| Model Size | ~16MB |
| GPU Memory Used | ~6-7GB / 8GB |

---

## Tips for Best Performance

1. **Close other applications** - Free up GPU memory
2. **Use FP16 (`--amp`)** - 2x faster, same accuracy
3. **Monitor GPU temp** - Should stay under 80¬∞C
4. **Keep drivers updated** - Latest NVIDIA drivers
5. **Use SSD** - Faster dataset loading

---

## After Training

### Evaluate Best Model:
```bash
python train_rtx.py -e --resume model_best_rtx.pth.tar FOOD101
```

### Compare with Baseline:
- Baseline: 76.3%
- Your model: 85-87%
- Improvement: +9-11% ‚úÖ

---

## üéâ Success!

With RTX 3070, you'll achieve **85-87% accuracy in just 3-7 hours** instead of 56 hours on MacBook!

**Ready to transfer and train!** üöÄ
